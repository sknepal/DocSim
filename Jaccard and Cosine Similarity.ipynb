{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Similarity Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d4</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          d1        d2        d3        d4\n",
       "d1  1.000000  1.000000  0.100000  0.428571\n",
       "d2  1.000000  1.000000  0.100000  0.428571\n",
       "d3  0.100000  0.100000  1.000000  0.363636\n",
       "d4  0.428571  0.428571  0.363636  1.000000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "def tokenize(text):\n",
    "    #remove full stops and commas\n",
    "    #lower the text and split it by spaces.\n",
    "    text = text.replace(\".\", \"\")\n",
    "    text = text.replace(\",\", \"\")\n",
    "    return text.lower().split()\n",
    "\n",
    "def jaccard(first_document, second_document):\n",
    "    #calculate jaccard similarity\n",
    "    intersection = set(first_document).intersection(set(second_document))\n",
    "    union = set(first_document).union(set(second_document))\n",
    "    return len(intersection)/len(union)\n",
    "\n",
    "d1 = \"I am Sam.\"\n",
    "d2 = \"Sam I am.\"\n",
    "d3 = \"I do not like green eggs and ham.\"\n",
    "d4 = \"I do not like them, Sam I am.\"\n",
    "\n",
    "documents_list = [d1, d2, d3, d4]\n",
    "tokenized_documents = [tokenize(doc) for doc in documents_list] # tokenize all the documents\n",
    "\n",
    "jaccard_list = {} # dictionary to store all the documents' jaccard similarity to each other.\n",
    "\n",
    "# append the document index as the key of the dictionary.\n",
    "for index, doc in enumerate(documents_list):\n",
    "    for index, doc in enumerate(documents_list):\n",
    "        jaccard_list[index] = {}\n",
    "\n",
    "# create a nested dictionary where the nested dictionary holds the jaccard similarity between the documents.\n",
    "# ie. {0 : {0: ..., 1: ..., 2:..., 3:...}, 1: {0: ..., 1: ..., 2:..., 3:...} and so on}\n",
    "for first_doc_index, doc in enumerate(documents_list):\n",
    "    for second_doc_index, doc in enumerate(documents_list):\n",
    "        jaccard_list[first_doc_index][second_doc_index] = jaccard(tokenized_documents[first_doc_index], tokenized_documents[second_doc_index])\n",
    "\n",
    "\n",
    "# show the result in a table\n",
    "overall_matrix = pd.DataFrame(jaccard_list)\n",
    "overall_matrix.columns = ['d1', 'd2', 'd3', 'd4']\n",
    "overall_matrix.index = ['d1', 'd2', 'd3', 'd4']\n",
    "print \"Jaccard Similarity Matrix\"\n",
    "overall_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d1</th>\n",
       "      <th>d2</th>\n",
       "      <th>d3</th>\n",
       "      <th>d4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084591</td>\n",
       "      <td>0.550447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084591</td>\n",
       "      <td>0.550447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d3</th>\n",
       "      <td>0.084591</td>\n",
       "      <td>0.084591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.400733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d4</th>\n",
       "      <td>0.550447</td>\n",
       "      <td>0.550447</td>\n",
       "      <td>0.400733</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          d1        d2        d3        d4\n",
       "d1  1.000000  1.000000  0.084591  0.550447\n",
       "d2  1.000000  1.000000  0.084591  0.550447\n",
       "d3  0.084591  0.084591  1.000000  0.400733\n",
       "d4  0.550447  0.550447  0.400733  1.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "def tf(term, document): # calculate term frequency\n",
    "    return document.count(term)\n",
    "\n",
    "def idf(documents): # calculate inverse document frequency\n",
    "    idf_value_list = {}\n",
    "    all_tokens = []\n",
    "    for sublist in tokenized_documents:\n",
    "        for item in sublist:\n",
    "            all_tokens.append(item) # go through all the documents and tokenize the texts\n",
    "            \n",
    "    all_tokens_set = set(all_tokens) # turn the tokenized texts into a set \n",
    "                                     # so that it only contains unique tokens\n",
    "    \n",
    "    for token in all_tokens_set:\n",
    "        token_exists = []\n",
    "        for sublist in tokenized_documents:\n",
    "            token_exists.append(token in sublist) # if a token exists in a document, mark it as 1 \n",
    "                                                 # on the token_exists list or else 0. \n",
    "        idf_value_list[token] = 1 + math.log(len(tokenized_documents)/(sum(token_exists)))\n",
    "                                                # idf formula. divide total number of documents by \n",
    "                                                # the number of documents where the token exists\n",
    "    return idf_value_list\n",
    "\n",
    "\n",
    "def tfidf(documents):\n",
    "    tfidf = []\n",
    "    tokenized_documents = [tokenize(doc) for doc in documents]\n",
    "    inverse_document_frequency = idf(tokenized_documents)\n",
    "    for document in tokenized_documents:\n",
    "        tfidf_doc = []\n",
    "        for term in inverse_document_frequency.keys():\n",
    "            term_frequency = tf(term, document)\n",
    "            tfidf_doc.append(term_frequency * inverse_document_frequency[term]) # tf * idf \n",
    "        tfidf.append(tfidf_doc)\n",
    "    return tfidf\n",
    "\n",
    "\n",
    "def cosine_similarity(first_word_vector, second_word_vector): # cosine similarity of two word vectors\n",
    "    return float(dot(first_word_vector,second_word_vector) / (norm(first_word_vector) * norm(second_word_vector)))\n",
    "   \n",
    "    \n",
    "# tfidf calculation of all documents\n",
    "tfidf_docs = tfidf(documents_list)\n",
    "\n",
    "\n",
    "# now, same as earlier with jaccard similarity, we are representing all the similarities in a table.\n",
    "\n",
    "cosine_similarity_list = {}\n",
    "\n",
    "for index, doc in enumerate(documents_list):\n",
    "    for index, doc in enumerate(documents_list):\n",
    "        cosine_similarity_list[index] = {}\n",
    "        \n",
    "for first_doc_index, doc in enumerate(documents_list):\n",
    "    for second_doc_index, doc in enumerate(documents_list):\n",
    "        cosine_similarity_list[first_doc_index][second_doc_index] = cosine_similarity(tfidf_docs[first_doc_index], tfidf_docs[second_doc_index])\n",
    "\n",
    "# show the result in a table\n",
    "overall_matrix = pd.DataFrame(cosine_similarity_list)\n",
    "overall_matrix.columns = ['d1', 'd2', 'd3', 'd4']\n",
    "overall_matrix.index = ['d1', 'd2', 'd3', 'd4']\n",
    "print \"Cosine Similarity Matrix\"\n",
    "overall_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
